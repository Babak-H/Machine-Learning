{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import randint\n",
    "import seaborn as sns # used for plot interactive graph. \n",
    "import matplotlib.pyplot as plt\n",
    "from io import StringIO\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Data : Consumer complaints received about financial products and services\n",
    "https://catalog.data.gov/dataset/consumer-complaint-database\n",
    "Each complaint has been labeled with a specific product and this is a supervised text classification problem\n",
    "'''\n",
    "\n",
    "df = pd.read_csv('complaints.csv')\n",
    "print(df.shape)  \n",
    "# (2062907, 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only select two meaningful columns\n",
    "df1 = df[['Product', 'Consumer complaint narrative']].copy()\n",
    "# drop null rows NaN\n",
    "df1 = df1[pd.notnull(df1['Consumer complaint narrative'])]\n",
    "# rename columns\n",
    "df1.columns = ['Product', 'Consumer_complaints']\n",
    "df1.shape \n",
    "# (705199, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of complaints that have text\n",
    "total = df1['Consumer_complaints'].notnull().sum()\n",
    "round((total / len(df) * 100), 2)  \n",
    "# 34.18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df.Product.unique()).values\n",
    "'''\n",
    "array([['Debt collection'],\n",
    "       ['Credit reporting, credit repair services, or other personal consumer reports'],\n",
    "       ['Checking or savings account'],\n",
    "       ['Credit card or prepaid card'],\n",
    "       ['Money transfer, virtual currency, or money service'],\n",
    "       ['Vehicle loan or lease'],\n",
    "       ['Mortgage'],\n",
    "       ['Student loan'],\n",
    "       ['Payday loan, title loan, or personal loan'],\n",
    "       ['Credit card'],\n",
    "       ['Consumer Loan'],\n",
    "       ['Payday loan'],\n",
    "       ['Bank account or service'],\n",
    "       ['Credit reporting'],\n",
    "       ['Other financial service'],\n",
    "       ['Money transfers'],\n",
    "       ['Prepaid card'],\n",
    "       ['Virtual currency']], dtype=object)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we sample the data, so it will take a shorter time to process\n",
    "df2 = df1.sample(10000, random_state=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming similar categories so it will be easier to classify them\n",
    "df2.replace({'Product': \n",
    "             {'Credit reporting, credit repair services, or other personal consumer reports': 'Credit reporting, repair, or other', \n",
    "              'Credit reporting': 'Credit reporting, repair, or other',\n",
    "              'Credit card': 'Credit card or prepaid card',\n",
    "              'Prepaid card': 'Credit card or prepaid card',\n",
    "              'Payday loan': 'Payday loan, title loan, or personal loan',\n",
    "              'Money transfer': 'Money transfer, virtual currency, or money service',\n",
    "              'Virtual currency': 'Money transfer, virtual currency, or money service'}}, \n",
    "            inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df2.Product.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product = class to guess | Consumer_complaints : text to classifiy based on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn each category of product into a seperate id\n",
    "df2['category_id'] = df2['Product'].factorize()[0]\n",
    "# get a list of 1-to-1 relation of Product, category_id\n",
    "category_id_df = df2[['Product', 'category_id']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "colors = ['grey','grey','grey','grey','grey','grey','grey','grey','grey',\n",
    "    'grey','darkblue','darkblue','darkblue']\n",
    "df2.groupby('Product').Consumer_complaints.count().sort_values().plot.barh(\n",
    "    ylim=0, color=colors, title= 'complaint count per category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we will use TFIDF to turn words into vectors\n",
    "'''\n",
    "min_df = remove the words from the vocabulary which have occured in less tahn 'min_df' number of files in corpuis\n",
    "max_df = remove words from vocab that have occured more than 'max_df' number of files\n",
    "sublinear_tf = set to True to scale the term frequency in logarithmic scale\n",
    "use_idf = weight factor must use inverse document frequency\n",
    "ngram_range =  (1,2) to indicate that unigrams and bigrams will be considered\n",
    "'''\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, ngram_range=(1,2), stop_words='english')\n",
    "features = tfidf.fit_transform(df2.Consumer_complaints).toarray()\n",
    "labels = df2.category_id\n",
    "\n",
    "print(features.shape)  #10000 complaint where each of them has 27973 features\n",
    "# (10000, 27973)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(features[0][f for f in featurez where f != 0])\n",
    "one = features[1]\n",
    "one[one > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_to_id = dict(category_id_df.values)\n",
    "id_to_category = dict(category_id_df[['category_id', 'Product']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_to_id.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.get_feature_names()[25:30]\n",
    "# ['00 account', '00 accounts', '00 added', '00 addition', '00 additional']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we want to meature the correlation between each label|product with complaint features\n",
    "N=3\n",
    "# .items() turns each dictionary key-val pair into a tuple\n",
    "for Product, category_id in sorted(category_to_id.items()):\n",
    "    features_chi2 = chi2(features, labels == category_id)\n",
    "    # sort features based on their corroleation to the labels\n",
    "    indices = np.argsort(features_chi2[0])\n",
    "    feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "    unigrams = [v for v in feature_names if len(v.split(' ')) == 1]  # when feature is one word\n",
    "    bigrams = [v for v in feature_names if len(v.split(' ')) == 2]   # when feature is two words\n",
    "    print(Product)\n",
    "    # show top 3 unigrams and bigrams for this label\n",
    "    print(', '.join(unigrams[-N:]))\n",
    "    print(', '.join(bigrams[-N:]))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Models\n",
    "* Random forest\n",
    "* SVM\n",
    "* Multinomial Naive Bayes\n",
    "* LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2['Consumer_complaints']\n",
    "y = df2['Product']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the models\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "\n",
    "# 5 Cross-validation\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "\n",
    "entries = []\n",
    "for model in models:\n",
    "  model_name = model.__class__.__name__\n",
    "  accuracies = cross_val_score(model, features, labels, scoring='accuracy', cv=CV)\n",
    "  for fold_idx, accuracy in enumerate(accuracies):\n",
    "    entries.append((model_name, fold_idx, accuracy))\n",
    "    \n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_accuracy = cv_df.groupby('model_name').accuracy.mean()\n",
    "'''\n",
    "LinearSVC               0.779103\n",
    "LogisticRegression      0.758114\n",
    "MultinomialNB           0.647500\n",
    "RandomForestClassifier  0.387005\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain with support vector machine, since it was the highest ranking model\n",
    "X_train, X_test, y_train, y_test,indices_train,indices_test = train_test_split(features, \n",
    "                                                               labels, \n",
    "                                                               df2.index, test_size=0.25, \n",
    "                                                               random_state=1)\n",
    "model = LinearSVC()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision, Recall, F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, y_pred, target_names=df2['Product'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state = 0)\n",
    "\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5,\n",
    "                        ngram_range=(1, 2), \n",
    "                        stop_words='english')\n",
    "fitted_vectorizer = tfidf.fit(X_train)\n",
    "tfidf_vectorizer_vectors = fitted_vectorizer.transform(X_train)\n",
    "model = LinearSVC().fit(tfidf_vectorizer_vectors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_complaint = \"\"\"I have been enrolled back at XXXX XXXX University in the XX/XX/XXXX. Recently, i have been harassed by \\\n",
    "Navient for the last month. I have faxed in paperwork providing them with everything they needed. And yet I am still getting \\\n",
    "phone calls for payments. Furthermore, Navient is now reporting to the credit bureaus that I am late. At this point, \\\n",
    "Navient needs to get their act together to avoid me taking further action. I have been enrolled the entire time and my \\\n",
    "deferment should be valid with my planned graduation date being the XX/XX/XXXX.\"\"\"\n",
    "\n",
    "print(model.predict(fitted_vectorizer.transform([new_complaint])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[df2['Consumer_complaint'] == new_complaint]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('uni': conda)",
   "name": "python3613jvsc74a57bd0db0c1a8a66b94ca2a4dcda03093850d4d191a9eb24a83ca13cd6513468003ee0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
